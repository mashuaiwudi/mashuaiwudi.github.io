<!DOCTYPE html>

<html lang="en" class="shuaima"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="">
    <link rel="stylesheet" href="./file/bootstrap.min.css">
    <link rel="stylesheet" href="./file/all.min.css">
    <base href=".">
    <title>Applying for Ph.d. offer in HCI</title>
    <style>
        body {
            margin-top: 20px;
            font-family:  sans-serif;
            font-weight: lighter;

        }

        a {
            color: black;
            border-bottom: 1px dotted black;
        }

        a:hover,
        a:active {
            color: #DB522F;
            text-decoration: none;
        }

        h1 a {
            color: #6B747C;
            border: none;
        }

        h2 {
            font-size: 1.5em;
            border-bottom: 2px solid;
        }
        
        h3 {
            font-size: 1.2em;
            color: #000000;
        }
        
        h4 {
            font-size: 1em;
            font-family:  sans-serif;
            font-weight: lighter;
            color: #000000;
            margin-top: 10px;
            margin-bottom: 30px;
        }

        .strong {
            color: #DB522F;
        }

        @media (max-width: 767.98px) {
            header {
                text-align: center;
            }
        }

        ul.social-icons {
            font-size: 1rem;
            margin-top: 24px;
            margin-bottom: 0;
        }

        ul.social-icons li::before {
            content: '[';
        }

        ul.social-icons li::after {
            content: ']';
        }

        ul.social-icons li a {
            border: none;
        }

        img.portrait {
            max-width: 100%;
        }

        @media (max-width: 767.98px) {
            img.portrait {
                display: block;
                max-width: 300px;
                margin: auto;
            }
        }
        
        .annotation
        {
            margin-top: -0.5em;
            margin-bottom: 0.5em;
            font-size: 12px;
            line-height: 12px;
        }

        .taxonomy img {
            max-width: 100%;
        }

        div.research-project {
            font-size: 14px;
            margin-bottom: 1.5rem;
        }
        
        div.line-of-research {
            background-color:#F0F0F0;
        }

        div.research-project video {
            max-width: 100%;
            margin-bottom: 0.5rem;
        }

        div.research-project p {
            margin-bottom: 0.3rem;
        }

        .news {
            font-size: 15px;
            margin-bottom: 0px;
        }

        #news-more {
            display: none;
        }

        .tweets {
            overflow: auto;
            -webkit-overflow-scrolling:touch;
        }

        .fun-projects img {
            max-width: 100%;
        }
        
        .info {
            border-style: none;
            font-weight: bold;
            color: #999;
        }
        
        hr.dash{
            border-top: 1px dashed #bbbbbb;
            margin-bottom: 15px;
            margin-top: 15px;
        }
        
		
    </style>

	
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script type="text/javascript" async="" src="./file/analytics.js"></script><script async="" src="./file/js"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-48610112-3');
	</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155884219-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-155884219-2');
    </script>


</head>

<body data-gr-c-s-loaded="true">
    <header class="container">
        <h1 class="float-md-left mb-0">
            <a href="https://shuaima.info/">Shuai Ma | 马帅</a>
        </h1>
        <ul class="list-inline float-md-right social-icons">
        	<li class="list-inline-item"><a href="project.htm">Project</a></li>
            <li class="list-inline-item"><a href="cv-shuaima.pdf">CV/Resume</a></li>
            <li class="list-inline-item"><a href="https://scholar.google.com/citations?hl=zh-CN&user=qajd8BYAAAAJ">Google
            Scholar</a></li>
            <li class="list-inline-item"><a href="https://twitter.com/shuaima_hci">Twitter</a></li>
            <li class="list-inline-item"><a href="mailto:mashuai171@mails.ucas.ac.cn">Email</a></li>
        </ul>
        <div class="clearfix"></div>
        <hr>
    </header>

    <div class="container">


        <div class="row mb-3">
        	<div class="col-lg-3 col-md-4">
                <img src="./file/1031-3.jpg" width="350">
            </div>
            <div class="offset-xl-1 col-xl-8 col-lg-9 col-md-8">
                <p>
                    Shuai Ma is a Master Degree candidate of Computer Science at Human-Computer Interaction Lab, Institute of Software, Chinese Academy of Sciences (ISCAS).
                </p>
                <p>
					His research goal is to bring advanced AI techniques closer to users by applying Human-centered AI into AI-empowered interactive systems to solve problems faced in the physical world. Specifically, his research interests include Human-centered AI, Mobile and Social Computing, Human-AI Collaboration and Human-in-the-loop Machine Learning, which enable a broad range of applications in healthcare, multimedia interaction, online learning, and a variety of daily tasks. He received his Bachelor's Degree in Software Engineering from Harbin Institute of Technology (HIT) with an honorable title of Top 10 undergraduates in HIT (Special Scholarship for Undergraduate, top 0.1%).
                </p>
                <p>
                    Shuai will graduate in 2020 Summer and he is applying for a Ph.D. offer in HCI.
                </p>
            </div>
            <!--
            <div class="row taxonomy">
                <div class="col-lg-6 mb-3">
                    <img src="./file/focus.png">
                </div>
            </div>
        -->
            <div>
        </div>


        <div class="row">
            <!-- left column -->
            <div class="col-lg-8 mb-2">
                <h2>Research</h2>

                <div class="row research-project">

                    <div class="col-md-4">
                        <video loop muted playsinline  width="250">
                            <source type="video/mp4" src="./file/媒体1.mp4">
                        </video>
                        
                    </div>
                    <div class="col-md-8">
                        <h6>
                            SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network
                        </h6>
                        <p class="text-muted">
                            <strong>Shuai Ma</strong>, Zijun Wei, Feng Tian, Xiangmin Fan, Jianming Zhang, Xiaohui Shen, Zhe Lin, Jin Huang, Radomír Měch, Dimitris Samaras, Hongan Wang (CHI 2019)
                            <a class="info" href="paper/SmartEye.pdf">[PDF]</a>
                        </p>
                        <p class="strong">
                            <img src="./file/hm.png" width="20"> Honorable Mention Award
                        </p>
                        <p>
                            Taking a high-quality photo needs composition skill which non-expert users lack. We present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. SmartEye integrates the View Proposal Network (VPN), a deep learning-based model that outputs composition suggestions in real-time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-4">
                        <img src="./file/research/reminder.png" width="250">
                    </div>
                    <div class="col-md-8">
                        <h6>
                            What Did I Miss? Assisting User-adaptive Missed Content Reviewing in MOOC Learning
                        </h6>
                        <p class="text-muted">
                            Qian Zhu, <strong>Shuai Ma</strong> (UIST 2019 Poster)
                            <a class="info" href="paper/What Did I Miss.pdf">[PDF]</a>
                        </p>
                        <p>
                            We present Reminder, a system for detecting divided attention and reminding learners what they just missed on both PC and mobile devices with a camera capturing their status.  We also propose a visualization method to help learners review missed content easily. User study shows that Reminder detects learners’ divided attention and assists them to review missed course contents effectively.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-4">
                        <img src="./file/research/pre-screen.png" width="250">
                    </div>
                    <div class="col-md-8">
                        <h6>
                            Pre-screen: Assisting Material Screening in Early-stage of Video Editing
                        </h6>
                        <p class="text-muted">
                            Qian Zhu, <strong>Shuai Ma</strong>, Cuixia Ma (UIST 2019 Poster)
                            <a class="info" href="https://www.youtube.com/watch?v=TL5vSKXKCwM">[Video]</a>
                            <a class="info" href="paper/Pre-screen.pdf">[PDF]</a>
                        </p>

                        <p>
                            In video editing, screening raw material is a time-consuming step. We present Pre-screen, which integrates several deep learning approaches to assist users to screen materials in the early-stage of video editting. A preliminary study was carefully conducted on users in the video editing domain. Based on the result, we well designed and implemented Pre-screen which provides 4 supported fuctions to better help users screen vide materials.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-4">
                        <img src="./file/research/mirroru.png" width="250">
                    </div>
                    <div class="col-md-8">
                        <h6>
                            mirrorU: Scaffolding Emotional Reflection via In-Situ Assessment and Interactive Feedback
                        </h6>
                        <p class="text-muted">
                            Liuping Wang, Xiangmin Fan, Feng Tian, Lingjia Deng, <strong>Shuai Ma</strong>, Jin Huang, Hongan Wang (CHI 2018 Poster)
                            <a class="info" href="paper/mirrorU.pdf">[PDF]</a>
                        </p>
                        <p>
                            We present mirrorU, a mobile system that supports users to reflect on and write about their daily emotional experience. While prior work has focused primarily on providing memory triggers or affective cues, mirrorU provides in-situ assessment and interactive feedback to scaffold reflective writing. 
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-4">
                        <img src="./file/research/pd.png" width="250">
                    </div>
                    <div class="col-md-8">
                        <h6>
                            Implicit Detection of Motor Impairment in Parkinson’s Disease from Everyday Smartphone Interactions 
                        </h6>
                        <p class="text-muted">
                            Jing Gao, Feng Tian, Junjun Fan, Dakuo Wang, Xiangmin Fan, Yicheng Zhu, <strong>Shuai Ma</strong>, Jin Huang, Hongan Wang (CHI 2018 Poster)
                            <a class="info" href="paper/pd.pdf">[PDF]</a>
                        </p>
                        <p>
                            In this work, we explored the feasibility and accuracy of detecting motor impairment in Parkinson’s disease (PD) via implicitly sensing and analyzing users’ everyday interactions with their smartphones. Through a 42 subjects study, our approach achieved an overall accuracy of 88.1% (90.0%/86.4% sensitivity/specificity) in discriminating PD subjects from age-matched healthy controls. 
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-4">
                        <img src="./file/research/pinggu.png" width="250">
                    </div>
                    <div class="col-md-8">
                        <h6>
                            Human-AI Interaction in Healthcare: Three Case Studies About How Patient(s) And Doctors Interact with AI in a Multi-Tiers Healthcare Network
                        </h6>
                        <p class="text-muted">
                            Yunzhi Li, Liuping Wang, <strong>Shuai Ma</strong>, Xiangmin Fan, Zijun Wang, Junfeng Jiao, Dakuo Wang (CHI 2019 Workshop: Unpacking the Infrastructuring Work of Patients and Caregivers around the World)
                            <a class="info" href="paper/chi19workshop.pdf">[PDF]</a>
                        </p>
                        <p>
                            We presents three ongoing research projects that aim to study how to design, develop, and evaluate the systems supporting human-AI interaction in the healthcare domain. Collaborating with the local government administrators, hospitals, clinics and doctors, we get a valuable opportunity to study and improve how AI-empowered technologies are changing people's life in providing or receiving healthcare services in a suburb district in Beijing, China.
                        </p>
                    </div>
                </div>

                <hr class="dash">

            </div>
            <!-- /left column -->
            <!-- right column -->
            <div class="col-lg-4 mb-2">
                <h2>Latest News</h2>
                <ul class="news">
                    <li>Dec 10 2019 | Two papers were rejected by IUI 2020.</li>
                    <li>Aug 27-30 2019 | Went to LyuLiang in Shanxi to help the poor children.</li>
                    <li>Aug 12 2019 | New semester started.</li>
                    <li>Aug 10 2019 | Celebrated birthday for my grandfather.</li>
                    <li>Aug 5 2019 | Had a nice trip in Weihai, a beautiful city along the sea.</li>
                    <li>May 9 2019 | Gave a talk at CHI 2019 conference.</li>
                    <li>Mar 15 2019 | One paper got CHI Honorable Mention Award!</li>
                </ul>
                <ul class="news" id="news-more">
                    <li>Dec 10 2018 | One paper got accepted at CHI 2019.</li>
                </ul>
                <a id="toggle-more-news" href="https://yangzhang.dev/#">More &gt;</a>

                <div class="mt-3 tweets">
                    <iframe id="twitter-widget-0" scrolling="yes" frameborder="0" allowtransparency="true" allowfullscreen="true" class="twitter-timeline twitter-timeline-rendered" style="position: static; visibility: visible; display: inline-block; width: 100%; height: 1000px; padding: 0px; border: none; max-width: 100%; min-width: 180px; margin-top: 0px; margin-bottom: 0px; min-height: 200px;" data-widget-id="profile:shuaihci" title="Twitter Timeline" src="shuai_tui.html"></iframe>
                    <script async="" src="file/widgets.js.下载" charset="utf-8"></script>
                </div>
            </div>
            <!-- /right column -->
        </div>

        <h2>A Glimpse of Life</h2>
            <div class="row fun-projects">
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/lyuliang1.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/1031-2.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/1031-4.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/huoguo1.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/7.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/6.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/1031-5.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/1031-6.png"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/1031-7.jpg"></a>
                </div>
                <div class="col-lg-2 col-md-3 col-6 mb-3">
                    <img src="file/life/1031-8.png"></a>
                </div>

            </div>
    </div>


<script src="./file/jquery.min.js"></script>
<script>
    $('#toggle-more-news').click(function () {
        $('#news-more').toggle();
        $('#news-more').is(':visible') ? $(this).text('< Hide') : $(this).text('More >');
        return false;
    });

    $(window).on('scroll', function () {
        $('video').each(function () {
            var video = $(this)[0];
            var rect = video.getBoundingClientRect();

            if (
                rect.top >= 0 && rect.left >= 0 &&
                rect.bottom <= $(window).height() &&
                rect.right <= $(window).width()
            ) {
                video.play();
            } else {
                video.pause();
            }
        });
    });
</script>

</body></html>