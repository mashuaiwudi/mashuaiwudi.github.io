<!DOCTYPE html>
<html lang="en" class="shuaima"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="./file/bootstrap.min.css">
    <link rel="stylesheet" href="./file/all.min.css">
    <base href=".">
    <title>Shuai Ma | Applying for Ph.d. offer in HCI</title>
    <style>
        body {
            margin-top: 20px;
			font-family:  Helvetica;

        }

        a {
            color: black;
            border-bottom: 1px dotted black;
        }

        a:hover,
        a:active {
            color: #0099FF;
            text-decoration: none;
        }

        h1 a {
            color: #0099FF;
            border: none;
        }

        h2 {
            font-size: 1.5em;
            border-bottom: 2px solid;
            color: #0099FF;
        }
        
        h3 {
            font-size: 1.2em;
			color: #0099FF;
        }
		
        h4 {
            font-size: 1em;
			font-family:  sans-serif;
			font-weight: lighter;
			color: #0099FF;
			margin-top: 10px;
			margin-bottom: 30px;
        }

        .strong {
            color: #0099FF;
        }

        @media (max-width: 767.98px) {
            header {
                text-align: center;
            }
        }

        ul.social-icons {
            font-size: 1rem;
            margin-top: 24px;
            margin-bottom: 0;
        }

        ul.social-icons li::before {
            content: '[';
        }

        ul.social-icons li::after {
            content: ']';
        }

        ul.social-icons li a {
            border: none;
        }

        img.portrait {
            max-width: 100%;
        }

        @media (max-width: 767.98px) {
            img.portrait {
                display: block;
                max-width: 300px;
                margin: auto;
            }
        }
		
		.annotation
		{
		    margin-top: -0.5em;
		    margin-bottom: 0.5em;
		    font-size: 12px;
			line-height: 12px;
		}

        .taxonomy img {
            max-width: 100%;
        }

        div.research-project {
            font-size: 14px;
            margin-bottom: 1.5rem;
        }
		
        div.line-of-research {
            background-color:#0099FF;
        }

        div.research-project video {
            max-width: 100%;
            margin-bottom: 0.5rem;
        }

        div.research-project p {
            margin-bottom: 0.3rem;
        }

        .news {
            font-size: 15px;
            margin-bottom: 0px;
        }

        #news-more {
            display: none;
        }

        .tweets {
            overflow: auto;
            -webkit-overflow-scrolling:touch;
        }

        .fun-projects img {
            max-width: 100%;
        }
        
        .info {
            border-style: none;
            font-weight: bold;
            color: #999;
        }
		
		hr.dash{
		    border-top: 1px dashed #bbbbbb;
		    margin-bottom: 15px;
		    margin-top: 15px;
		    color: #0099FF;
		}
        
		
    </style>

	
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script type="text/javascript" async="" src="./file/analytics.js"></script><script async="" src="./file/js"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-48610112-3');
	</script>

</head>

<body data-gr-c-s-loaded="true">
    <header class="container">
        <h1 class="float-md-left mb-0">
            <a href="https://shuaima.top/">Shuai Ma | 马帅</a>
        </h1>
        <ul class="list-inline float-md-right social-icons">
            <li class="list-inline-item"><a href="index.htm">Bio</a></li>
            <li class="list-inline-item"><a href="cv-shuaima.pdf">CV/Resume</a></li>
            <li class="list-inline-item"><a href="mailto:mashuai171@mails.ucas.ac.cn">Email</a></li>
        </ul>
        <div class="clearfix"></div>
        <hr>
    </header>

    <div class="container">


            <div>
                <h2>Research</h2>

                <div class="alert alert-secondary">
                    <h3>Personalization/User Modeling and Interactive Machine/Deep Learning</h3>
                    <div>
                        Every user has a difference from others. In many subjective tasks, users have significant differences and preferences. To help users do a task, a general model is usually built using ML or DL methods. However, these models are trained by data from all kinds of users, which is not suitable for a specific user. So, modeling users' personalities or preferences can be important. How to make a general model suitable for a specific user is an interesting research question.
                    </div>
                </div>

                <div class="row research-project">

                    <div class="col-md-3">
                    	<video loop muted playsinline  width="250">
                            <source type="video/mp4" src="./file/媒体1.mp4">
                        </video>
						
                    </div>
                    <div class="col-md-9">
                        <h6>
                            SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network
                        </h6>
                        <p class="text-muted">
                            <strong>Shuai Ma</strong>, Zijun Wei, Feng Tian, Xiangmin Fan, Jianming Zhang, Xiaohui Shen, Zhe Lin, Jin Huang, Radomír Měch, Dimitris Samaras, Hongan Wang (CHI 2019)
                            <a class="info" href="paper/SmartEye.pdf">[PDF]</a>
                        </p>
                        <p class="strong">
                            <img src="./file/hm.png" width="20"> Honorable Mention Award
                        </p>
                        <p>
                            Taking a high-quality photo needs composition skill which non-expert users lack. We present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. SmartEye integrates the View Proposal Network (VPN), a deep learning-based model that outputs composition suggestions in real-time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/pbayes.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            User Adaptive Modeling in 2D Moving Target Selection 
                        </h6>
                        <p>
                            Our previous work has proposed a method to help 2D moving target selection. However, it used a general model trained by all users' data collected. When a new user uses our tool, it may be not suitable for him. So we designed a personalized user modeling method to adapt the general model to a specific user.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="alert alert-secondary">
                    <h3>Human-centered AI Techniques for MOOC Learning</h3>
                    <div>
                        Compared with offline classes, MOOC learning has its shortages such as high dropout rates and lack of individualized assessment and feedback. One of the big reasons is that users are easily distracted when taking MOOC lessons compared with classroom education as there is no teacher monitoring learners’ disengagement. We investigate a) how to adaptive review based on missed content, b) how to personalize AI-based algorithm for better performance in MOOCs, and c) what effect do imperfect AI-based algorithms have on learners.
                    </div>
                </div>

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/reminder.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            What Did I Miss? Assisting User-adaptive Missed Content Reviewing in MOOC Learning
                        </h6>
                        <p class="text-muted">
                            <strong>Shuai Ma</strong> (UIST 2019 EA)
                            <a class="info" href="paper/whatmiss.pdf">[PDF]</a>
                        </p>
                        <p>
                            In Massive Open Online Courses (MOOCs), learners face a lot of distractions which will cause divided attention (DA). However, it is not easy for learners to realize that they are distracted and to find out which part of the course they have missed. In this paper, we present Reminder, a system for detecting divided attention and reminding learners what they just missed on both PC and mobile devices with a camera capturing their status. To get learners’ attention level, we build a regression model to predict attention score from an integrated feature vector. Meanwhile, we design an interactively updating method to make the model adaptive to a specific user. We also propose a visualization method to help learners review missed content easily. User study shows that Reminder detects learners’ divided attention and assists them to review missed course contents effectively.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/remindme.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            RemindMe: Personalizing Imperfect AI-based Engagement Prediction Algorithm in MOOC Learning
                        </h6>
                        <p class="text-muted">
                            <strong>Shuai Ma*</strong>, Feng Tian
                            <a class="info">[Submit to IUI2020]</a>
                        </p>
                        <p>
                            In Massive Open Online Courses (MOOCs), distractions can easily happen to learners, which can be partially alleviated by monitoring the attention level of users and reminding them. However, an engagement prediction algorithm is not always accurate. What influences the performance of the algorithm and how to make it work better? To explore this problem, we first design a prototype, Reminder, which integrates a deep learning model to monitor learners’ engagement and remind them of the distraction. Based on it, we conduct a preliminary user study. Results show that the difference in users’ viewing habits is an important factor leading to the inaccuracy of the algorithm. We then propose RemindMe, a novel user-adaptive tool to personalize the general engagement prediction algorithm implicitly in real-time. User study results show that RemindMe not only provides users a reminder accurately and efficiently but also learns their viewing habits progressively as interacting with them.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/whyremindme.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Why Remind Me? IWas Not Distracted: Investigating How Imperfect AI-based Engagement Prediction Algorithm Affect Users in MOOC Learning
                        </h6>
                        <p class="text-muted">
                            <strong>Shuai Ma*</strong>, Feng Tian
                            <a class="info">[Submit to IUI2020]</a>
                        </p>
                        <p>
                            In MOOC learning, since engagement prediction technologies are not perfect, what impact do inaccurate reminders have on users in both the learning processes and learning outcomes? To explore this problem, we first propose Reminder, a novel tool to monitor users’ attention implicitly in realtime and remind them of disengagement. Then, we purposefully adjust the Recall/Precision of the back-end algorithm to investigate the effect of engagement prediction algorithms with different performances on users’ learning processes and outcomes quantitatively. User study results show that with similar accuracy, a high recall algorithm achieves generally better reminding effects than a high precision one but the latter brings users a more satisfactory experience.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="alert alert-secondary">
                    <h3>Human-computer interaction in Healthcare</h3>
                    <div>
                        Many early stages of the disease are difficult to detect, but some symptoms can be sensitively captured by sensors. So we developed some methods of human-computer interaction to capture users' limb movement through mobile phones, Kinect and other devices, and collect a large number of data of normal users and patients, so as to achieve an assistant diagnosis of diseases.
                    </div>
                </div>

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/pd.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Implicit Detection of Motor Impairment in Parkinson’s Disease from Everyday Smartphone Interactions 
                        </h6>
                        <p class="text-muted">
                            Jing Gao, Feng Tian, Junjun Fan, Dakuo Wang, Xiangmin Fan, Yicheng Zhu, <strong>Shuai Ma</strong>, Jin Huang, Hongan Wang (CHI 2018 Poster)
                            <a class="info" href="paper/pd.pdf">[PDF]</a>
                        </p>
                        <p>
                            In this work, we explored the feasibility and accuracy of detecting motor impairment in Parkinson’s disease (PD) via implicitly sensing and analyzing users’ everyday interactions with their smartphones. Through a 42 subjects study, our approach achieved an overall accuracy of 88.1% (90.0%/86.4% sensitivity/specificity) in discriminating PD subjects from age-matched healthy controls. 
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-3">
                        <video loop muted playsinline  width="250">
                            <source type="video/mp4" src="./file/demo.mp4">
                        </video>
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Identifying Gait Abnormality with a Single Click
                        </h6>
                        <p class="text-muted">
                            Jin Huang, <strong>Shuai Ma</strong>, Feng Tian, Xiang Li, Jie Liu, Hongan Wang (SCIENCE CHINA)
                            <a class="info">[To appear]</a>
                        </p>
                        <p>
                            Gait abnormality is one of the major symptoms of nervous system diseases such as Parkinson’s disease. In the clinic, assessments tools usually require patients to complete a long and tedious testing process under the supervision of a doctor, which is tremendous pressure for both patients and hospitals. We propose a novel system, which integrates identity recognition algorithm, behavior recognition algorithm, and built-in gait detection model to accelerate the clinical diagnosis process.
                        </p>
                    </div>
                </div>

                <hr class="dash">
                
                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/pinggu.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Human-AI Interaction in Healthcare: Three Case Studies About How Patient(s) And Doctors Interact with AI in a Multi-Tiers Healthcare Network
                        </h6>
                        <p class="text-muted">
                            Yunzhi Li, Liuping Wang, <strong>Shuai Ma</strong>, Xiangmin Fan, Zijun Wang, Junfeng Jiao, Dakuo Wang (CHI 2019 Workshop)
                            <a class="info" href="paper/chi19workshop.pdf">[PDF]</a>
                        </p>
                        <p>
                            We presents three ongoing research projects that aim to study how to design, develop, and evaluate the systems supporting human-AI interaction in the healthcare domain. Collaborating with the local government administrators, hospitals, clinics and doctors, we get a valuable opportunity to study and improve how AI-empowered technologies are changing people's life in providing or receiving healthcare services in a suburb district in Beijing, China. We hope this work will ground the discussion with other participants in the workshop and build further collaborations with the health informatics community.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="alert alert-secondary">
                    <h3>Video Interaction</h3>
                    <div>
                        To further utilize the video resources, we developed some interactive methods for video viewing, video editing, MOOC learning, etc.
                    </div>
                </div>


                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/co-lighter.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Co-Lighter: Promoting Video Watching by Crowd Suggestion on Specific Content
                        </h6>
                        <p class="text-muted">
                            <strong>Shuai Ma*</strong>, Feng Tian
                            <a class="info">[Submit to CSCW2019]</a>
                        </p>
                        <p>
                            In this research, we first conduct a preliminary survey among 114 participants to investigate the limits in current video watching modes. Then, based on the survey results, we present Co-Lighter, a novel tool for video viewing and comment. Co-Lighter supports viewers to watch videos and share feelings about video content in a collaborative way. 
                        </p>
                    </div>
                </div>

                <hr class="dash">




                <div class="alert alert-secondary">
                    <h3>Interaction Technique for Daily Life</h3>
                    <div>
                        Interaction is everywhere in our daily life. What can it do to create a better life?
                    </div>
                </div>

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/mirroru.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            mirrorU: Scaffolding Emotional Reflection via In-Situ Assessment and Interactive Feedback
                        </h6>
                        <p class="text-muted">
                            Liuping Wang, Xiangmin Fan, Feng Tian, Lingjia Deng, <strong>Shuai Ma</strong>, Jin Huang, Hongan Wang (CHI 2018 Poster)
                            <a class="info" href="paper/mirrorU.pdf">[PDF]</a>
                        </p>
                        <p>
                            We present mirrorU, a mobile system that supports users to reflect on and write about their daily emotional experience. While prior work has focused primarily on providing memory triggers or affective cues, mirrorU provides in-situ assessment and interactive feedback to scaffold reflective writing. 
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="alert alert-secondary">
                    <h3>Interaction Technique for Touch and Design</h3>
                    <div>
                        We proposed some systems for design and gesture recognition.
                    </div>
                </div>

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/furniture.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Upcycle-Chic: A Software Tool for Ideating Furniture Upcycling Design
                        </h6>
                        <p class="text-muted">
                            <a class="info">[Submit to UIST2019]</a>
                        </p>
                        <p>
                            We present Upcycle-Chic, a design and visualization environment that allows a user to view possible upcycling solutions for a given piece of old furniture and explore varying design variations. These possible solutions are generated based on design strategies drawn from over 1000 examples on the web and books shared by professionals and hobbyist furniture makers.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/recognizer.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Chronos: Improving Recognizers’ Performance by Leveraging Gesture Continuity and Designers’ Involvement
                        </h6>
                        <p class="text-muted">
                            <a class="info">[Submit to IUI2019]</a>
                        </p>
                        <p>
                            We present Chronos, an algorithm framework that improves the performance of gesture recognizers by 1) extracting the continuity information from gesture sequences and, 2) enabling designers to optimize the decision-making rewards. The framework is implemented by integrating a dynamic Bayesian network (DBN) with a partially observable Markov decision process (POMDP).
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="alert alert-secondary">
                    <h3>Human Engagement and Trust with AI</h3>
                    <div>
                        When collaborating with AI, how will users feel and do they trust AI? To investigate these questions, we did some interesting research.
                    </div>
                </div>

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/woman.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Conversational Agents as Emotional Supporter in a Pregnant Women Online Community
                        </h6>
                        <p class="text-muted">
                            <a class="info">[Submit to CHI2020]</a>
                        </p>
                        <p>
                            Online health communities (OHCs) for pregnancy care have emerged as essential resources for pregnant women to seek social support. However, many of the help-seeking posts can not get timely responses from the community members. Advances in artificial intelligence open an opportunity for OHCs to simulate an active member by a chatbot that automatically responds to these posts. To explore this possibility, we create an EmosBot that generates replies to provide emotional support to pregnant women whose posts get no reply.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                <div class="row research-project">

                    <div class="col-md-3">
                        <img src="./file/research/cdss.png" width="250">
                    </div>
                    <div class="col-md-9">
                        <h6>
                            Human-AI Collaboration in Healthcare: How Clinicians Work with an AI-Empowered Clinical Decision Support System
                        </h6>
                        <p class="text-muted">
                            <a class="info">[Submit to CHI2020]</a>
                        </p>
                        <p>
                            The advancement of AI technologies in recent years is changing the landscape of healthcare systems. In the U.S., AI empowered clinical decision support systems (AI-CDSS) have been proven capable of making diagnosis with scan image data for particular types of cancer. In this paper, we provide an empirical account by studying users’ perception and interaction with a recently deployed AI-CDSS system in rural China.
                        </p>
                    </div>
                </div>

                <hr class="dash">

                

                


            </div>
            

        </div>
    </div>

<script src="./file/jquery.min.js"></script>
<script>
    $('#toggle-more-news').click(function () {
        $('#news-more').toggle();
        $('#news-more').is(':visible') ? $(this).text('< Hide') : $(this).text('More >');
        return false;
    });

    $(window).on('scroll', function () {
        $('video').each(function () {
            var video = $(this)[0];
            var rect = video.getBoundingClientRect();

            if (
                rect.top >= 0 && rect.left >= 0 &&
                rect.bottom <= $(window).height() &&
                rect.right <= $(window).width()
            ) {
                video.play();
            } else {
                video.pause();
            }
        });
    });
</script>

</body></html>